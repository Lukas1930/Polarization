{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from modules import ps\n",
    "import numpy as np\n",
    "import sys\n",
    "import functions\n",
    "import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "import umap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "congresses= ['095', '096', '097','098', '099', '100', '101', '102', '103','104', '105', '106', '107','108', '109', '110', '111', '112','113', '114', '115', '116','117','118']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarization on the nominate score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinions distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_polarization_across_congresses_avg_party(congresses, data_path, output_path, \n",
    "                               methods=[\"pca\", \"mds\", \"umap\"]):\n",
    "    \"\"\"\n",
    "    Calculates and compares polarization across congresses using dimensionality reduction and NOMINATE scores.\n",
    "    Uses pre-existing network edge lists created by construct_congress_network().\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    congresses : list\n",
    "        List of congress numbers (e.g., ['111', '112', '113'])\n",
    "    data_path : str\n",
    "        Path to the data directory\n",
    "    output_path : str\n",
    "        Path to save output files\n",
    "    methods : list\n",
    "        List of dimensionality reduction methods to use: 'pca', 'mds', 'umap'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing polarization scores for each congress and method\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store polarization scores for each congress\n",
    "    polarization_results = {}\n",
    "    \n",
    "    # Process each congress\n",
    "    for congress in congresses:\n",
    "        print(f\"\\nProcessing {congress}th Congress...\")\n",
    "        congress_polarization = {}\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Load the edge list for the network\n",
    "            edge_file = f\"{data_path}H{congress}_USA_edgelist.csv\"\n",
    "            edge_df = pd.read_csv(edge_file)\n",
    "            print(f\"Loaded edge list for {congress}th Congress with {len(edge_df)} edges\")\n",
    "            \n",
    "            # Clean up edge data - ensure numeric values\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Source'], errors='coerce').notna()]\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Target'], errors='coerce').notna()]\n",
    "            \n",
    "            # Convert to numeric and create graph\n",
    "            edge_df['Source'] = edge_df['Source'].astype(int)\n",
    "            edge_df['Target'] = edge_df['Target'].astype(int)\n",
    "            G = nx.from_pandas_edgelist(edge_df, 'Source', 'Target')\n",
    "            print(f\"Created network with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "            \n",
    "            # Step 2: Load the member data with NOMINATE scores\n",
    "            members_file = f\"./data/USA/raw/H{congress}_members.csv\"\n",
    "            members_df = pd.read_csv(members_file)\n",
    "            members_df = members_df.drop_duplicates(subset=['icpsr'])\n",
    "            members_df['icpsr'] = members_df['icpsr'].astype(int)\n",
    "            print(f\"Loaded {len(members_df)} members for {congress}th Congress\")\n",
    "            \n",
    "            # Step 3: Calculate polarization using NOMINATE scores\n",
    "            if 'nominate_dim1' in members_df.columns:\n",
    "                # Create a dictionary of NOMINATE scores\n",
    "                nominate_opinions = dict(zip(members_df['icpsr'], members_df['nominate_dim1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                nominate_opinions = {k: v for k, v in nominate_opinions.items() \n",
    "                                   if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                pol_score = ps.ge(nominate_opinions, {}, G)\n",
    "                congress_polarization['nominate'] = pol_score\n",
    "                print(f\"NOMINATE polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            # Step 4: Load the voting data for dimensionality reduction\n",
    "            votes_file = f\"./data/USA/Filtered/H{congress}_filtered_USA_votes.csv\"\n",
    "            votes_df = pd.read_csv(votes_file)\n",
    "            print(f\"Loaded {len(votes_df)} votes for {congress}th Congress\")\n",
    "            \n",
    "            # Step 5: Create a sparse matrix of votes\n",
    "            reps = votes_df['icpsr'].unique()\n",
    "            roll_calls = votes_df['rollnumber'].unique()\n",
    "            \n",
    "            rep_to_idx = {rep: i for i, rep in enumerate(reps)}\n",
    "            roll_to_idx = {roll: j for j, roll in enumerate(roll_calls)}\n",
    "            \n",
    "            row_indices = []\n",
    "            col_indices = []\n",
    "            values = []\n",
    "            \n",
    "            for _, row in votes_df.iterrows():\n",
    "                rep_idx = rep_to_idx[row['icpsr']]\n",
    "                roll_idx = roll_to_idx[row['rollnumber']]\n",
    "                row_indices.append(rep_idx)\n",
    "                col_indices.append(roll_idx)\n",
    "                values.append(row['cast_code'])\n",
    "            \n",
    "            # Create the sparse matrix\n",
    "            sparse_matrix = csr_matrix((values, (row_indices, col_indices)), \n",
    "                                      shape=(len(reps), len(roll_calls)))\n",
    "            \n",
    "            # Create a DataFrame linking sparse matrix rows to representative IDs\n",
    "            sparse_df = pd.DataFrame({'icpsr': reps})\n",
    "            \n",
    "            # Step 6: Perform dimensionality reduction for each method\n",
    "            if 'pca' in methods:\n",
    "                print(\"Performing PCA...\")\n",
    "                pca = PCA(n_components=2)\n",
    "                pca_result = pca.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['pca_1'] = pca_result[:, 0]\n",
    "                sparse_df['pca_2'] = pca_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using PCA\n",
    "                sparse_df['icpsr'] = sparse_df['icpsr'].astype(int)\n",
    "                pca_opinions = dict(zip(sparse_df['icpsr'], sparse_df['pca_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                pca_opinions = {k: v for k, v in pca_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if pca_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(pca_opinions.values())\n",
    "                    max_val = max(pca_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        pca_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in pca_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(pca_opinions_norm, {}, G)\n",
    "                        congress_polarization['pca'] = pol_score\n",
    "                        print(f\"PCA polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'mds' in methods:\n",
    "                print(\"Performing MDS...\")\n",
    "                mds = MDS(n_components=2, random_state=42, n_jobs=-1)\n",
    "                mds_result = mds.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['mds_1'] = mds_result[:, 0]\n",
    "                sparse_df['mds_2'] = mds_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using MDS\n",
    "                mds_opinions = dict(zip(sparse_df['icpsr'], sparse_df['mds_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                mds_opinions = {k: v for k, v in mds_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if mds_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(mds_opinions.values())\n",
    "                    max_val = max(mds_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        mds_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in mds_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(mds_opinions_norm, {}, G)\n",
    "                        congress_polarization['mds'] = pol_score\n",
    "                        print(f\"MDS polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'umap' in methods:\n",
    "                print(\"Performing UMAP...\")\n",
    "                reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "                umap_result = reducer.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['umap_1'] = umap_result[:, 0]\n",
    "                sparse_df['umap_2'] = umap_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using UMAP\n",
    "                umap_opinions = dict(zip(sparse_df['icpsr'], sparse_df['umap_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                umap_opinions = {k: v for k, v in umap_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if umap_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(umap_opinions.values())\n",
    "                    max_val = max(umap_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        umap_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in umap_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(umap_opinions_norm, {}, G)\n",
    "                        congress_polarization['umap'] = pol_score\n",
    "                        print(f\"UMAP polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            # Save results for this congress\n",
    "            polarization_results[congress] = congress_polarization\n",
    "            \n",
    "            # Save the dimensionality reduction results for future use\n",
    "            sparse_df.to_csv(f\"{output_path}H{congress}_dimensionality_reduction.csv\", index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {congress}th Congress: {e}\")\n",
    "    pol_df = pd.DataFrame.from_dict(polarization_results, orient='index')\n",
    "    pol_df = pol_df.reset_index().rename(columns={'index': 'congress'})\n",
    "    pol_df['congress_num'] = pol_df['congress'].astype(int)\n",
    "    pol_df = pol_df.sort_values('congress_num').set_index('congress')\n",
    "    pol_df = pol_df.drop('congress_num', axis=1)\n",
    "    pol_df.to_csv(f\"{output_path}polarization_scores.csv\")\n",
    "    print(f\"Saved polarization data to {output_path}polarization_scores.csv\")\n",
    "    \n",
    "    return polarization_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_polarization_across_congresses_avg_party(congresses, data_path=\"./data/USA/avg_party/\", output_path=\"data/USA/avg_party/results/\", edges=\"edgelist\", suffix=\"USA\", h= \"H\", h1 = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_polarization_across_congresses_inter_intra(congresses, data_path, output_path, \n",
    "                               methods=[\"pca\", \"mds\", \"umap\"]):\n",
    "    \"\"\"\n",
    "    Calculates and compares polarization across congresses using dimensionality reduction and NOMINATE scores.\n",
    "    Uses pre-existing network edge lists created by construct_congress_network().\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    congresses : list\n",
    "        List of congress numbers (e.g., ['111', '112', '113'])\n",
    "    data_path : str\n",
    "        Path to the data directory\n",
    "    output_path : str\n",
    "        Path to save output files\n",
    "    methods : list\n",
    "        List of dimensionality reduction methods to use: 'pca', 'mds', 'umap'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing polarization scores for each congress and method\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store polarization scores for each congress\n",
    "    polarization_results = {}\n",
    "    \n",
    "    # Process each congress\n",
    "    for congress in congresses:\n",
    "        print(f\"\\nProcessing {congress}th Congress...\")\n",
    "        congress_polarization = {}\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Load the edge list for the network\n",
    "            edge_file = f\"{data_path}congress{congress}_edges.csv\"\n",
    "            edge_df = pd.read_csv(edge_file)\n",
    "            print(f\"Loaded edge list for {congress}th Congress with {len(edge_df)} edges\")\n",
    "            \n",
    "            # Clean up edge data - ensure numeric values\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Source'], errors='coerce').notna()]\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Target'], errors='coerce').notna()]\n",
    "            \n",
    "            # Convert to numeric and create graph\n",
    "            edge_df['Source'] = edge_df['Source'].astype(int)\n",
    "            edge_df['Target'] = edge_df['Target'].astype(int)\n",
    "            G = nx.from_pandas_edgelist(edge_df, 'Source', 'Target')\n",
    "            print(f\"Created network with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "            \n",
    "            # Step 2: Load the member data with NOMINATE scores\n",
    "            members_file = f\"./data/USA/raw/H{congress}_members.csv\"\n",
    "            members_df = pd.read_csv(members_file)\n",
    "            members_df = members_df.drop_duplicates(subset=['icpsr'])\n",
    "            members_df['icpsr'] = members_df['icpsr'].astype(int)\n",
    "            print(f\"Loaded {len(members_df)} members for {congress}th Congress\")\n",
    "            \n",
    "            # Step 3: Calculate polarization using NOMINATE scores\n",
    "            if 'nominate_dim1' in members_df.columns:\n",
    "                # Create a dictionary of NOMINATE scores\n",
    "                nominate_opinions = dict(zip(members_df['icpsr'], members_df['nominate_dim1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                nominate_opinions = {k: v for k, v in nominate_opinions.items() \n",
    "                                   if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                pol_score = ps.ge(nominate_opinions, {}, G)\n",
    "                congress_polarization['nominate'] = pol_score\n",
    "                print(f\"NOMINATE polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            # Step 4: Load the voting data for dimensionality reduction\n",
    "            votes_file = f\"./data/USA/Filtered/H{congress}_filtered_USA_votes.csv\"\n",
    "            votes_df = pd.read_csv(votes_file)\n",
    "            print(f\"Loaded {len(votes_df)} votes for {congress}th Congress\")\n",
    "            \n",
    "            # Step 5: Create a sparse matrix of votes\n",
    "            reps = votes_df['icpsr'].unique()\n",
    "            roll_calls = votes_df['rollnumber'].unique()\n",
    "            \n",
    "            rep_to_idx = {rep: i for i, rep in enumerate(reps)}\n",
    "            roll_to_idx = {roll: j for j, roll in enumerate(roll_calls)}\n",
    "            \n",
    "            row_indices = []\n",
    "            col_indices = []\n",
    "            values = []\n",
    "            \n",
    "            for _, row in votes_df.iterrows():\n",
    "                rep_idx = rep_to_idx[row['icpsr']]\n",
    "                roll_idx = roll_to_idx[row['rollnumber']]\n",
    "                row_indices.append(rep_idx)\n",
    "                col_indices.append(roll_idx)\n",
    "                values.append(row['cast_code'])\n",
    "            \n",
    "            # Create the sparse matrix\n",
    "            sparse_matrix = csr_matrix((values, (row_indices, col_indices)), \n",
    "                                      shape=(len(reps), len(roll_calls)))\n",
    "            \n",
    "            # Create a DataFrame linking sparse matrix rows to representative IDs\n",
    "            sparse_df = pd.DataFrame({'icpsr': reps})\n",
    "            \n",
    "            # Step 6: Perform dimensionality reduction for each method\n",
    "            if 'pca' in methods:\n",
    "                print(\"Performing PCA...\")\n",
    "                pca = PCA(n_components=2)\n",
    "                pca_result = pca.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['pca_1'] = pca_result[:, 0]\n",
    "                sparse_df['pca_2'] = pca_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using PCA\n",
    "                sparse_df['icpsr'] = sparse_df['icpsr'].astype(int)\n",
    "                pca_opinions = dict(zip(sparse_df['icpsr'], sparse_df['pca_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                pca_opinions = {k: v for k, v in pca_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if pca_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(pca_opinions.values())\n",
    "                    max_val = max(pca_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        pca_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in pca_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(pca_opinions_norm, {}, G)\n",
    "                        congress_polarization['pca'] = pol_score\n",
    "                        print(f\"PCA polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'mds' in methods:\n",
    "                print(\"Performing MDS...\")\n",
    "                mds = MDS(n_components=2, random_state=42, n_jobs=-1)\n",
    "                mds_result = mds.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['mds_1'] = mds_result[:, 0]\n",
    "                sparse_df['mds_2'] = mds_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using MDS\n",
    "                mds_opinions = dict(zip(sparse_df['icpsr'], sparse_df['mds_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                mds_opinions = {k: v for k, v in mds_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if mds_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(mds_opinions.values())\n",
    "                    max_val = max(mds_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        mds_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in mds_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(mds_opinions_norm, {}, G)\n",
    "                        congress_polarization['mds'] = pol_score\n",
    "                        print(f\"MDS polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'umap' in methods:\n",
    "                print(\"Performing UMAP...\")\n",
    "                reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "                umap_result = reducer.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['umap_1'] = umap_result[:, 0]\n",
    "                sparse_df['umap_2'] = umap_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using UMAP\n",
    "                umap_opinions = dict(zip(sparse_df['icpsr'], sparse_df['umap_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                umap_opinions = {k: v for k, v in umap_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if umap_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(umap_opinions.values())\n",
    "                    max_val = max(umap_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        umap_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in umap_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(umap_opinions_norm, {}, G)\n",
    "                        congress_polarization['umap'] = pol_score\n",
    "                        print(f\"UMAP polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            # Save results for this congress\n",
    "            polarization_results[congress] = congress_polarization\n",
    "            \n",
    "            # Save the dimensionality reduction results for future use\n",
    "            sparse_df.to_csv(f\"{output_path}H{congress}_dimensionality_reduction.csv\", index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {congress}th Congress: {e}\")\n",
    "    pol_df = pd.DataFrame.from_dict(polarization_results, orient='index')\n",
    "    pol_df = pol_df.reset_index().rename(columns={'index': 'congress'})\n",
    "    pol_df['congress_num'] = pol_df['congress'].astype(int)\n",
    "    pol_df = pol_df.sort_values('congress_num').set_index('congress')\n",
    "    pol_df = pol_df.drop('congress_num', axis=1)\n",
    "    pol_df.to_csv(f\"{output_path}polarization_scores.csv\")\n",
    "    print(f\"Saved polarization data to {output_path}polarization_scores.csv\")\n",
    "    \n",
    "    return polarization_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_polarization_across_congresses_inter_intra(congresses, data_path=\"./data/USA/intra_inter_party/\", output_path=\"data/USA/intra_inter_party/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denmark\n",
    "def D_analyze_polarization_across_congresses_avg(congresses, data_path, output_path, \n",
    "                               methods=[\"pca\", \"mds\", \"umap\"]):\n",
    "    \"\"\"\n",
    "    Calculates and compares polarization across congresses using dimensionality reduction and NOMINATE scores.\n",
    "    Uses pre-existing network edge lists created by construct_congress_network().\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    congresses : list\n",
    "        List of congress numbers (e.g., ['111', '112', '113'])\n",
    "    data_path : str\n",
    "        Path to the data directory\n",
    "    output_path : str\n",
    "        Path to save output files\n",
    "    methods : list\n",
    "        List of dimensionality reduction methods to use: 'pca', 'mds', 'umap'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing polarization scores for each congress and method\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store polarization scores for each congress\n",
    "    polarization_results = {}\n",
    "    \n",
    "    # Process each congress\n",
    "    for congress in congresses:\n",
    "        print(f\"\\nProcessing {congress}th Congress...\")\n",
    "        congress_polarization = {}\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Load the edge list for the network\n",
    "            edge_file = f\"{data_path}/P{congress}_DK_edgelist.csv\"\n",
    "            edge_df = pd.read_csv(edge_file)\n",
    "            print(f\"Loaded edge list for {congress}th Congress with {len(edge_df)} edges\")\n",
    "            \n",
    "            # Clean up edge data - ensure numeric values\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Source'], errors='coerce').notna()]\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Target'], errors='coerce').notna()]\n",
    "            \n",
    "            # Convert to numeric and create graph\n",
    "            edge_df['Source'] = edge_df['Source'].astype(int)\n",
    "            edge_df['Target'] = edge_df['Target'].astype(int)\n",
    "            G = nx.from_pandas_edgelist(edge_df, 'Source', 'Target')\n",
    "            print(f\"Created network with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "            \n",
    "            \n",
    "\n",
    "            # Step 4: Load the voting data for dimensionality reduction\n",
    "            votes_file = f\"data/Denmark/Raw/P{congress}_DK.csv\"\n",
    "            votes_df = pd.read_csv(votes_file)\n",
    "            print(f\"Loaded {len(votes_df)} votes for {congress}th Congress\")\n",
    "            \n",
    "            # Step 5: Create a sparse matrix of votes\n",
    "            reps = votes_df['aktørid'].unique()\n",
    "            roll_calls = votes_df['afstemningid'].unique()\n",
    "            \n",
    "            rep_to_idx = {rep: i for i, rep in enumerate(reps)}\n",
    "            roll_to_idx = {roll: j for j, roll in enumerate(roll_calls)}\n",
    "            \n",
    "            row_indices = []\n",
    "            col_indices = []\n",
    "            values = []\n",
    "            \n",
    "            for _, row in votes_df.iterrows():\n",
    "                rep_idx = rep_to_idx[row['aktørid']]\n",
    "                roll_idx = roll_to_idx[row['afstemningid']]\n",
    "                row_indices.append(rep_idx)\n",
    "                col_indices.append(roll_idx)\n",
    "                values.append(row['typeid_x'])\n",
    "            \n",
    "            # Create the sparse matrix\n",
    "            sparse_matrix = csr_matrix((values, (row_indices, col_indices)), \n",
    "                                      shape=(len(reps), len(roll_calls)))\n",
    "            \n",
    "            # Create a DataFrame linking sparse matrix rows to representative IDs\n",
    "            sparse_df = pd.DataFrame({'aktørid': reps})\n",
    "            \n",
    "            # Step 6: Perform dimensionality reduction for each method\n",
    "            if 'pca' in methods:\n",
    "                print(\"Performing PCA...\")\n",
    "                pca = PCA(n_components=2)\n",
    "                pca_result = pca.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['pca_1'] = pca_result[:, 0]\n",
    "                sparse_df['pca_2'] = pca_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using PCA\n",
    "                sparse_df['aktørid'] = sparse_df['aktørid'].astype(int)\n",
    "                pca_opinions = dict(zip(sparse_df['aktørid'], sparse_df['pca_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                pca_opinions = {k: v for k, v in pca_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if pca_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(pca_opinions.values())\n",
    "                    max_val = max(pca_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        pca_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in pca_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(pca_opinions_norm, {}, G)\n",
    "                        congress_polarization['pca'] = pol_score\n",
    "                        print(f\"PCA polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'mds' in methods:\n",
    "                print(\"Performing MDS...\")\n",
    "                mds = MDS(n_components=2, random_state=42, n_jobs=-1)\n",
    "                mds_result = mds.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['mds_1'] = mds_result[:, 0]\n",
    "                sparse_df['mds_2'] = mds_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using MDS\n",
    "                mds_opinions = dict(zip(sparse_df['aktørid'], sparse_df['mds_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                mds_opinions = {k: v for k, v in mds_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if mds_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(mds_opinions.values())\n",
    "                    max_val = max(mds_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        mds_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in mds_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(mds_opinions_norm, {}, G)\n",
    "                        congress_polarization['mds'] = pol_score\n",
    "                        print(f\"MDS polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'umap' in methods:\n",
    "                print(\"Performing UMAP...\")\n",
    "                reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "                umap_result = reducer.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['umap_1'] = umap_result[:, 0]\n",
    "                sparse_df['umap_2'] = umap_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using UMAP\n",
    "                umap_opinions = dict(zip(sparse_df['aktørid'], sparse_df['umap_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                umap_opinions = {k: v for k, v in umap_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if umap_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(umap_opinions.values())\n",
    "                    max_val = max(umap_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        umap_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in umap_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(umap_opinions_norm, {}, G)\n",
    "                        congress_polarization['umap'] = pol_score\n",
    "                        print(f\"UMAP polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            # Save results for this congress\n",
    "            polarization_results[congress] = congress_polarization\n",
    "            \n",
    "            # Save the dimensionality reduction results for future use\n",
    "            sparse_df.to_csv(f\"{output_path}P{congress}_dimensionality_reduction.csv\", index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {congress}th Congress: {e}\")\n",
    "    \n",
    "\n",
    "    pol_df = pd.DataFrame.from_dict(polarization_results, orient='index')\n",
    "    pol_df = pol_df.reset_index().rename(columns={'index': 'congress'})\n",
    "    pol_df.to_csv(f\"{output_path}polarization_scores.csv\")\n",
    "    print(f\"Saved polarization data to {output_path}polarization_scores.csv\")\n",
    "            \n",
    "    \n",
    "    return polarization_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "period = ['01_05','05_07','07_11','11_15','15_19','19_22', \"22_present\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 01_05th Congress...\n",
      "Loaded edge list for 01_05th Congress with 13994 edges\n",
      "Created network with 187 nodes and 6997 edges\n",
      "Loaded 29487 votes for 01_05th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 2.1729\n",
      "Performing MDS...\n",
      "MDS polarization: 1.7477\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 2.4432\n",
      "\n",
      "Processing 05_07th Congress...\n",
      "Loaded edge list for 05_07th Congress with 18118 edges\n",
      "Created network with 215 nodes and 9059 edges\n",
      "Loaded 135901 votes for 05_07th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 2.3456\n",
      "Performing MDS...\n",
      "MDS polarization: 2.2926\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 5.0181\n",
      "\n",
      "Processing 07_11th Congress...\n",
      "Loaded edge list for 07_11th Congress with 26414 edges\n",
      "Created network with 238 nodes and 13207 edges\n",
      "Loaded 187400 votes for 07_11th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 0.9816\n",
      "Performing MDS...\n",
      "MDS polarization: 1.0448\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 1.7001\n",
      "\n",
      "Processing 11_15th Congress...\n",
      "Loaded edge list for 11_15th Congress with 24816 edges\n",
      "Created network with 226 nodes and 12408 edges\n",
      "Loaded 183908 votes for 11_15th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 0.8483\n",
      "Performing MDS...\n",
      "MDS polarization: 0.9740\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 0.9373\n",
      "\n",
      "Processing 15_19th Congress...\n",
      "Loaded edge list for 15_19th Congress with 13480 edges\n",
      "Created network with 230 nodes and 6740 edges\n",
      "Loaded 208401 votes for 15_19th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 1.6356\n",
      "Performing MDS...\n",
      "MDS polarization: 1.5789\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 2.1838\n",
      "\n",
      "Processing 19_22th Congress...\n",
      "Loaded edge list for 19_22th Congress with 18402 edges\n",
      "Created network with 216 nodes and 9201 edges\n",
      "Loaded 164342 votes for 19_22th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 0.8583\n",
      "Performing MDS...\n",
      "MDS polarization: 0.9978\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 1.1809\n",
      "\n",
      "Processing 22_presentth Congress...\n",
      "Loaded edge list for 22_presentth Congress with 15830 edges\n",
      "Created network with 223 nodes and 7915 edges\n",
      "Loaded 116900 votes for 22_presentth Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 1.4213\n",
      "Performing MDS...\n",
      "MDS polarization: 1.4255\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 1.4692\n",
      "Saved polarization data to data/Denmark/avg_party/results/polarization_scores.csv\n"
     ]
    }
   ],
   "source": [
    "results = D_analyze_polarization_across_congresses_avg(period, data_path=\"data/Denmark/avg_party/\", output_path=\"data/Denmark/avg_party/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denmark\n",
    "def D_analyze_polarization_across_congresses_intra_inter(congresses, data_path, output_path, \n",
    "                               methods=[\"pca\", \"mds\", \"umap\"]):\n",
    "    \"\"\"\n",
    "    Calculates and compares polarization across congresses using dimensionality reduction and NOMINATE scores.\n",
    "    Uses pre-existing network edge lists created by construct_congress_network().\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    congresses : list\n",
    "        List of congress numbers (e.g., ['111', '112', '113'])\n",
    "    data_path : str\n",
    "        Path to the data directory\n",
    "    output_path : str\n",
    "        Path to save output files\n",
    "    methods : list\n",
    "        List of dimensionality reduction methods to use: 'pca', 'mds', 'umap'\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing polarization scores for each congress and method\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Dictionary to store polarization scores for each congress\n",
    "    polarization_results = {}\n",
    "    \n",
    "    # Process each congress\n",
    "    for congress in congresses:\n",
    "        print(f\"\\nProcessing {congress}th Congress...\")\n",
    "        congress_polarization = {}\n",
    "        \n",
    "        try:\n",
    "            # Step 1: Load the edge list for the network\n",
    "            edge_file = f\"{data_path}/congress_{congress}_edges.csv\"\n",
    "            edge_df = pd.read_csv(edge_file)\n",
    "            print(f\"Loaded edge list for {congress}th Congress with {len(edge_df)} edges\")\n",
    "            \n",
    "            # Clean up edge data - ensure numeric values\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Source'], errors='coerce').notna()]\n",
    "            edge_df = edge_df[pd.to_numeric(edge_df['Target'], errors='coerce').notna()]\n",
    "            \n",
    "            # Convert to numeric and create graph\n",
    "            edge_df['Source'] = edge_df['Source'].astype(int)\n",
    "            edge_df['Target'] = edge_df['Target'].astype(int)\n",
    "            G = nx.from_pandas_edgelist(edge_df, 'Source', 'Target')\n",
    "            print(f\"Created network with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges\")\n",
    "            \n",
    "            \n",
    "\n",
    "            # Step 4: Load the voting data for dimensionality reduction\n",
    "            votes_file = f\"data/Denmark/Raw/P{congress}_DK.csv\"\n",
    "            votes_df = pd.read_csv(votes_file)\n",
    "            print(f\"Loaded {len(votes_df)} votes for {congress}th Congress\")\n",
    "            \n",
    "            # Step 5: Create a sparse matrix of votes\n",
    "            reps = votes_df['aktørid'].unique()\n",
    "            roll_calls = votes_df['afstemningid'].unique()\n",
    "            \n",
    "            rep_to_idx = {rep: i for i, rep in enumerate(reps)}\n",
    "            roll_to_idx = {roll: j for j, roll in enumerate(roll_calls)}\n",
    "            \n",
    "            row_indices = []\n",
    "            col_indices = []\n",
    "            values = []\n",
    "            \n",
    "            for _, row in votes_df.iterrows():\n",
    "                rep_idx = rep_to_idx[row['aktørid']]\n",
    "                roll_idx = roll_to_idx[row['afstemningid']]\n",
    "                row_indices.append(rep_idx)\n",
    "                col_indices.append(roll_idx)\n",
    "                values.append(row['typeid_x'])\n",
    "            \n",
    "            # Create the sparse matrix\n",
    "            sparse_matrix = csr_matrix((values, (row_indices, col_indices)), \n",
    "                                      shape=(len(reps), len(roll_calls)))\n",
    "            \n",
    "            # Create a DataFrame linking sparse matrix rows to representative IDs\n",
    "            sparse_df = pd.DataFrame({'aktørid': reps})\n",
    "            \n",
    "            # Step 6: Perform dimensionality reduction for each method\n",
    "            if 'pca' in methods:\n",
    "                print(\"Performing PCA...\")\n",
    "                pca = PCA(n_components=2)\n",
    "                pca_result = pca.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['pca_1'] = pca_result[:, 0]\n",
    "                sparse_df['pca_2'] = pca_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using PCA\n",
    "                sparse_df['aktørid'] = sparse_df['aktørid'].astype(int)\n",
    "                pca_opinions = dict(zip(sparse_df['aktørid'], sparse_df['pca_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                pca_opinions = {k: v for k, v in pca_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if pca_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(pca_opinions.values())\n",
    "                    max_val = max(pca_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        pca_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in pca_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(pca_opinions_norm, {}, G)\n",
    "                        congress_polarization['pca'] = pol_score\n",
    "                        print(f\"PCA polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'mds' in methods:\n",
    "                print(\"Performing MDS...\")\n",
    "                mds = MDS(n_components=2, random_state=42, n_jobs=-1)\n",
    "                mds_result = mds.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['mds_1'] = mds_result[:, 0]\n",
    "                sparse_df['mds_2'] = mds_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using MDS\n",
    "                mds_opinions = dict(zip(sparse_df['aktørid'], sparse_df['mds_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                mds_opinions = {k: v for k, v in mds_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if mds_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(mds_opinions.values())\n",
    "                    max_val = max(mds_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        mds_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in mds_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(mds_opinions_norm, {}, G)\n",
    "                        congress_polarization['mds'] = pol_score\n",
    "                        print(f\"MDS polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            if 'umap' in methods:\n",
    "                print(\"Performing UMAP...\")\n",
    "                reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "                umap_result = reducer.fit_transform(sparse_matrix.toarray())\n",
    "                sparse_df['umap_1'] = umap_result[:, 0]\n",
    "                sparse_df['umap_2'] = umap_result[:, 1]\n",
    "                \n",
    "                # Calculate polarization using UMAP\n",
    "                umap_opinions = dict(zip(sparse_df['aktørid'], sparse_df['umap_1']))\n",
    "                \n",
    "                # Filter for nodes in the graph and valid values\n",
    "                umap_opinions = {k: v for k, v in umap_opinions.items() \n",
    "                              if k in G.nodes and not pd.isna(v)}\n",
    "                \n",
    "                if umap_opinions:\n",
    "                    # Normalize to [-1, 1]\n",
    "                    min_val = min(umap_opinions.values())\n",
    "                    max_val = max(umap_opinions.values())\n",
    "                    if min_val != max_val:  # Avoid division by zero\n",
    "                        umap_opinions_norm = {\n",
    "                            k: 2 * (v - min_val) / (max_val - min_val) - 1\n",
    "                            for k, v in umap_opinions.items()\n",
    "                        }\n",
    "                        \n",
    "                        # Calculate polarization\n",
    "                        pol_score = ps.ge(umap_opinions_norm, {}, G)\n",
    "                        congress_polarization['umap'] = pol_score\n",
    "                        print(f\"UMAP polarization: {pol_score:.4f}\")\n",
    "            \n",
    "            # Save results for this congress\n",
    "            polarization_results[congress] = congress_polarization\n",
    "            \n",
    "            # Save the dimensionality reduction results for future use\n",
    "            sparse_df.to_csv(f\"{output_path}P{congress}_dimensionality_reduction.csv\", index=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {congress}th Congress: {e}\")\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "    pol_df = pd.DataFrame.from_dict(polarization_results, orient='index')\n",
    "    pol_df = pol_df.reset_index().rename(columns={'index': 'congress'})\n",
    "    pol_df.to_csv(f\"{output_path}polarization_scores.csv\")\n",
    "    print(f\"Saved polarization data to {output_path}polarization_scores.csv\")\n",
    "            \n",
    "    \n",
    "    return polarization_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 01_05th Congress...\n",
      "Loaded edge list for 01_05th Congress with 2702 edges\n",
      "Created network with 108 nodes and 2702 edges\n",
      "Loaded 29487 votes for 01_05th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 7.8369\n",
      "Performing MDS...\n",
      "MDS polarization: 4.0812\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 6.9138\n",
      "\n",
      "Processing 05_07th Congress...\n",
      "Loaded edge list for 05_07th Congress with 4358 edges\n",
      "Created network with 138 nodes and 4358 edges\n",
      "Loaded 135901 votes for 05_07th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 1.9770\n",
      "Performing MDS...\n",
      "MDS polarization: 1.6886\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 2.8309\n",
      "\n",
      "Processing 07_11th Congress...\n",
      "Loaded edge list for 07_11th Congress with 4908 edges\n",
      "Created network with 148 nodes and 4908 edges\n",
      "Loaded 187400 votes for 07_11th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 1.9269\n",
      "Performing MDS...\n",
      "MDS polarization: 1.9443\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 2.0746\n",
      "\n",
      "Processing 11_15th Congress...\n",
      "Loaded edge list for 11_15th Congress with 4852 edges\n",
      "Created network with 152 nodes and 4852 edges\n",
      "Loaded 183908 votes for 11_15th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 1.7846\n",
      "Performing MDS...\n",
      "MDS polarization: 1.7879\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 1.5417\n",
      "\n",
      "Processing 15_19th Congress...\n",
      "Loaded edge list for 15_19th Congress with 3956 edges\n",
      "Created network with 144 nodes and 3956 edges\n",
      "Loaded 208401 votes for 15_19th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 2.7317\n",
      "Performing MDS...\n",
      "MDS polarization: 2.1700\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 3.5806\n",
      "\n",
      "Processing 19_22th Congress...\n",
      "Loaded edge list for 19_22th Congress with 4194 edges\n",
      "Created network with 139 nodes and 4194 edges\n",
      "Loaded 164342 votes for 19_22th Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 1.9038\n",
      "Performing MDS...\n",
      "MDS polarization: 2.1069\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 2.3958\n",
      "\n",
      "Processing 22_presentth Congress...\n",
      "Loaded edge list for 22_presentth Congress with 4254 edges\n",
      "Created network with 147 nodes and 4254 edges\n",
      "Loaded 116900 votes for 22_presentth Congress\n",
      "Performing PCA...\n",
      "PCA polarization: 2.2669\n",
      "Performing MDS...\n",
      "MDS polarization: 2.0147\n",
      "Performing UMAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/jonashansen/Documents/ITU/Bachelor_git/venv/lib/python3.13/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP polarization: 2.6451\n",
      "Saved polarization data to data/Denmark/intra_inter_party/results/polarization_scores.csv\n"
     ]
    }
   ],
   "source": [
    "results = D_analyze_polarization_across_congresses_intra_inter(period, data_path=\"data/Denmark/intra_inter_party/\", output_path=\"data/Denmark/intra_inter_party/results/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
