{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from modules import ps\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/kubic/Desktop/machine learning/Polarization/\")\n",
    "\n",
    "import functions\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "import umap\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_edges(df):\n",
    "    df = df.groupby(by = [\"rollnumber\", \"cast_code\"]).apply(lambda x: pd.DataFrame(list(combinations(x[\"icpsr\"], 2)))) # \"combinations\" makes all possible pairs of icpsr codes for every vote value\n",
    "    df.columns = (\"src\", \"trg\")\n",
    "    df = df.groupby(by = [\"src\", \"trg\"]).size().reset_index().rename(columns = {0: \"nij\"})                        # Counts how many times a pair of congressmen appears in df (i.e. they co-voted)\n",
    "    return df\n",
    "\n",
    "def make_pdfs(edges, nodes):\n",
    "    party_lookup = nodes.set_index(\"icpsr\")[\"party_code\"].to_dict()\n",
    "    edges[\"party_src\"] = edges[\"src\"].map(party_lookup)\n",
    "    edges[\"party_trg\"] = edges[\"trg\"].map(party_lookup)\n",
    "    edges[\"same_party\"] = edges[\"party_src\"] == edges[\"party_trg\"]\n",
    "    edges[\"nij\"] /= edges[\"nij\"].max()  # Normalize co-vote counts\n",
    "\n",
    "    sp_pdf = gaussian_kde(edges[edges[\"same_party\"]][\"nij\"])\n",
    "    cp_pdf = gaussian_kde(edges[~edges[\"same_party\"]][\"nij\"])\n",
    "    return edges, sp_pdf, cp_pdf\n",
    "\n",
    "def find_intersection(kde1, kde2, init_interval=0.01, scope=[0.4,1], convergence=0.0001):\n",
    "    x_left, x_right = scope[0], scope[0] + init_interval\n",
    "    while x_right < scope[1]:\n",
    "        left, right = kde1(x_left)[0] - kde2(x_left)[0], kde1(x_right)[0] - kde2(x_right)[0]\n",
    "        if left * right < 0:\n",
    "            if init_interval <= convergence:\n",
    "                return x_right\n",
    "            return find_intersection(kde1, kde2, init_interval / 10, [x_left, x_right])\n",
    "        x_left, x_right = x_right, x_right + init_interval\n",
    "    return scope[0]\n",
    "\n",
    "def save_network(edges, congress, threshold, output_folder):\n",
    "    edges = edges[edges[\"nij\"] > threshold]\n",
    "    edges = edges[[\"src\", \"trg\"]].astype(int)\n",
    "    \n",
    "    edges_output = os.path.join(output_folder, f\"congress{congress}_edges.csv\")\n",
    "    edges.to_csv(edges_output, sep=\",\", index=False, header=False)\n",
    "    \n",
    "    print(f\"Network saved: {edges_output}\")\n",
    "\n",
    "def process_congresses(congress_list, input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for congress in congress_list:\n",
    "        print(f\"Processing Congress {congress}...\")\n",
    "        input_votes = os.path.join(input_folder, f\"H{congress}_filtered_USA_votes.csv\")\n",
    "        \n",
    "        if not os.path.exists(input_votes):\n",
    "            print(f\"Warning: Data file for Congress {congress} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load data\n",
    "        votes_df = pd.read_csv(input_votes)\n",
    "\n",
    "        # Create edgelist\n",
    "        edges_df = make_all_edges(votes_df)\n",
    "\n",
    "        # Generate PDFs\n",
    "        edges_df, sp_pdf, cp_pdf = make_pdfs(edges_df, votes_df)\n",
    "\n",
    "        # Compute intersection (threshold)\n",
    "        threshold = find_intersection(sp_pdf, cp_pdf)\n",
    "\n",
    "        # Save network\n",
    "        save_network(edges_df, congress, threshold, output_folder)\n",
    "\n",
    "# List of congress numbers\n",
    "congresses = ['097']\n",
    "\n",
    "# Run the process\n",
    "input_folder = \"Data/USA/Filtered/\"\n",
    "output_folder = \"Data/USA/Micheles/\"\n",
    "\n",
    "process_congresses(congresses, input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pol(congress, data_path=\"data/USA/Raw/\", edge_list_folder=\"Data/USA/Micheles/\"):\n",
    "    edge_list_file = os.path.join(edge_list_folder, f\"congress{congress}_edges.csv\")\n",
    "    \n",
    "    if not os.path.exists(edge_list_file):\n",
    "        print(f\"Warning: Edge list for Congress {congress} not found, skipping.\")\n",
    "        return None  # Skip if no edge list exists\n",
    "\n",
    "    edge_df = pd.read_csv(edge_list_file, header=None, names=['Source', 'Target'])\n",
    "\n",
    "    # Create the graph\n",
    "    G = nx.from_pandas_edgelist(edge_df, 'Source', 'Target')\n",
    "\n",
    "    # Convert nodes to integers\n",
    "    G = nx.relabel_nodes(G, lambda x: int(x))\n",
    "\n",
    "    # Load members' data\n",
    "    members_file = os.path.join(data_path, f\"H{congress}_members.csv\")\n",
    "    if not os.path.exists(members_file):\n",
    "        print(f\"Warning: Members file for Congress {congress} not found, skipping.\")\n",
    "        return None\n",
    "\n",
    "    members_df = pd.read_csv(members_file).dropna(subset=[\"nominate_dim1\"])\n",
    "    members_df[\"icpsr\"] = members_df[\"icpsr\"].astype(int)\n",
    "\n",
    "    # Create dictionary of opinions\n",
    "    opinions_x = dict(zip(members_df[\"icpsr\"], members_df[\"nominate_dim1\"]))\n",
    "\n",
    "    # Filter only existing nodes in the graph\n",
    "    opinions = {node: opinions_x[node] for node in G.nodes if node in opinions_x}\n",
    "\n",
    "    if not opinions:  # If no valid opinions exist, skip\n",
    "        print(f\"Warning: No valid opinions found for Congress {congress}, skipping.\")\n",
    "        return None\n",
    "\n",
    "    # Normalize opinions between -1 and 1\n",
    "    min_opinion, max_opinion = min(opinions.values()), max(opinions.values())\n",
    "    opinions = {k: 2 * (v - min_opinion) / (max_opinion - min_opinion) - 1 for k, v in opinions.items()}\n",
    "\n",
    "    # Compute polarization score\n",
    "    pol_score = ps.ge(opinions, {}, G)\n",
    "    \n",
    "    return pol_score\n",
    "congresses =  ['095', '096', '097','098', '099', '100', '101', '102', '103','104', '105', '106', '107','108', '109', '110', '111', '112','113', '114', '115', '116','117','118']\n",
    "\n",
    "\n",
    "pol_scores = {}\n",
    "for congress in congresses:\n",
    "    pol_score = calc_pol(congress)  # Run function\n",
    "    pol_scores[int(congress)] = pol_score  \n",
    "    print(f\"Congress {int(congress)}: Polarization Score = {pol_score}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(pol_scores.keys(), pol_scores.values(), marker='o', linestyle='-', color='b', label=\"Polarization Score\")\n",
    "plt.xlabel(\"Congress\")\n",
    "plt.ylabel(\"Polarization Score\")\n",
    "plt.title(\"Polarization Score by Congress\")\n",
    "plt.xticks(list(pol_scores.keys()))  # Set x-axis labels to be congress numbers\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
