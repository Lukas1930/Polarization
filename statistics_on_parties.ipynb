{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import os\n",
    "from matplotlib.colors import ListedColormap, Normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USA Statistics Per Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "congresses =  ['095', '096', '097','098', '099', '100', '101', '102', '103','104',\n",
    "               '105', '106', '107','108', '109', '110', '111', '112','113', '114',\n",
    "               '115', '116','117','118'] \n",
    "\n",
    "input_folder = \"Data/USA/Filtered\"\n",
    "output_folder = \"Images/heatmaps_party_agreement_USA\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for congress in congresses:\n",
    "    file_path = f\"{input_folder}/H{congress}_filtered_USA_votes.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Only keep 'yes' and 'no' votes from two main parties\n",
    "    df = df[df[\"cast_code\"].isin([1, 2])]\n",
    "    df = df[df[\"party_code\"].isin([100, 200])]\n",
    "\n",
    "    vote_counts = df.groupby([\"party_code\", \"rollnumber\", \"cast_code\"]).size().unstack(fill_value=0)\n",
    "    vote_counts.columns = [\"no_votes\", \"yes_votes\"]\n",
    "    vote_counts[\"total_votes\"] = vote_counts[\"no_votes\"] + vote_counts[\"yes_votes\"]\n",
    "    vote_counts[\"agreement_rate\"] = vote_counts[[\"no_votes\", \"yes_votes\"]].max(axis=1) / vote_counts[\"total_votes\"]\n",
    "\n",
    "    pivot_data = vote_counts.reset_index().pivot_table(\n",
    "        index=\"rollnumber\", columns=\"party_code\", values=\"agreement_rate\", fill_value=0\n",
    "    )\n",
    "\n",
    "    # Create a masked array to handle zeros\n",
    "    masked_data = pivot_data.copy()\n",
    "    mask = masked_data == 0\n",
    "\n",
    "    # Create a colormap where values == 0 appear black\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    cmap = cmap(np.linspace(0, 1, 256))\n",
    "    cmap[0] = [0, 0, 0, 1]  # Set the first (lowest) color to black\n",
    "    custom_cmap = ListedColormap(cmap)\n",
    "\n",
    "    # Normalize the data, ensuring 0 maps to index 0 in colormap\n",
    "    from matplotlib.colors import Normalize\n",
    "    norm = Normalize(vmin=0, vmax=1)\n",
    "\n",
    "    # Plot and save\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(pivot_data, cmap=custom_cmap, norm=norm, cbar=True)\n",
    "    plt.title(f\"Party Agreement Rate by Roll Call – {congress}th Congress\")\n",
    "    plt.xlabel(\"Party Code\")\n",
    "    plt.ylabel(\"Roll Number\")\n",
    "\n",
    "    output_path = os.path.join(output_folder, f\"agreement_heatmap_congress{congress}.png\")\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danish Statistics Per Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "congresses = ['01_05','05_07','07_11','11_15','15_19','19_22']\n",
    "input_folder = \"Data/Denmark/Raw\"\n",
    "output_folder = \"Images/heatmaps_party_agreement_danish\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for congress in congresses:\n",
    "    input_votes = f\"{input_folder}/P{congress}_DK.csv\"\n",
    "    df = pd.read_csv(input_votes)\n",
    "\n",
    "    # Filter only Yes (1) and No (2) votes\n",
    "    df = df[df[\"typeid_x\"].isin([1, 2])]\n",
    "\n",
    "    # Group and count votes\n",
    "    vote_counts = df.groupby([\"party\", \"afstemningid\", \"typeid_x\"]).size().unstack(fill_value=0)\n",
    "\n",
    "    # Rename columns\n",
    "    vote_counts.columns = [\"no_votes\", \"yes_votes\"]\n",
    "\n",
    "    # Calculate totals and agreement rates\n",
    "    vote_counts[\"total_votes\"] = vote_counts[\"no_votes\"] + vote_counts[\"yes_votes\"]\n",
    "    vote_counts[\"agreement_rate\"] = vote_counts[[\"no_votes\", \"yes_votes\"]].max(axis=1) / vote_counts[\"total_votes\"]\n",
    "\n",
    "    # Pivot data for heatmap\n",
    "    pivot_data = vote_counts.reset_index().pivot_table(\n",
    "        index=\"afstemningid\", columns=\"party\", values=\"agreement_rate\", fill_value=0\n",
    "    )\n",
    "\n",
    "    # Create a custom colormap: 0 values -> black, rest -> coolwarm\n",
    "    base_cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    base_array = base_cmap(np.linspace(0, 1, 256))\n",
    "    base_array[0] = [0, 0, 0, 1]  # Set first color (0) to black\n",
    "    custom_cmap = ListedColormap(base_array)\n",
    "\n",
    "    norm = Normalize(vmin=0, vmax=1)\n",
    "\n",
    "    # Plot and save\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(pivot_data, cmap=custom_cmap, norm=norm, cbar=True)\n",
    "    plt.title(f\"Party Agreement Rate by Roll Call – Denmark {congress}\")\n",
    "    plt.xlabel(\"Party\")\n",
    "    plt.ylabel(\"Roll Number\")\n",
    "\n",
    "    output_path = os.path.join(output_folder, f\"agreement_heatmap_dk_{congress}.png\")\n",
    "    plt.savefig(output_path, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA_edgelist = pd.read_csv(\"USA_edgelist.csv\")  \n",
    "Denmark_edgelist = pd.read_csv(\"Denmark_edgelist.csv\")\n",
    "G_USA = nx.from_pandas_edgelist(USA_edgelist, source=\"Source\", target=\"Target\")\n",
    "G_Denmark = nx.from_pandas_edgelist(Denmark_edgelist, source=\"Source\", target=\"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== USA Network Statistics ===\n",
      "Number of Nodes: 442\n",
      "Number of Edges: 27113\n",
      "Density: 0.2782\n",
      "Top 5 Most Connected Nodes (Degree Centrality): [(21993, 0.4557823129251701), (21948, 0.4557823129251701), (21375, 0.45351473922902497), (20519, 0.45351473922902497), (22161, 0.45124716553287986)]\n",
      "Top 5 Most Influential Nodes (Betweenness Centrality): [(21993, 0.4991629862342669), (21718, 0.4965380768296815), (22383, 0.3934476466575691), (22334, 0.05156348527223958), (21367, 0.039756511082800726)]\n",
      "Top 5 Most Influential Nodes (Eigenvector Centrality): [(21948, 0.0775347192328533), (22368, 0.07736423889976839), (21375, 0.07736084091397669), (31101, 0.07733350883193064), (21508, 0.07726795923561838)]\n",
      "Average Clustering Coefficient: 0.8423\n",
      "\n",
      "=== Denmark Network Statistics ===\n",
      "Number of Nodes: 220\n",
      "Number of Edges: 6657\n",
      "Density: 0.2763\n",
      "Top 5 Most Connected Nodes (Degree Centrality): [(12, 0.5525114155251141), (217, 0.5114155251141552), (20384, 0.5068493150684932), (20382, 0.502283105022831), (172, 0.502283105022831)]\n",
      "Top 5 Most Influential Nodes (Betweenness Centrality): [(21076, 0.07065509271010162), (21075, 0.07065509271010162), (20559, 0.04877158967376476), (20599, 0.047447310943642136), (20349, 0.0414012569073378)]\n",
      "Top 5 Most Influential Nodes (Eigenvector Centrality): [(217, 0.10230544853290544), (16503, 0.1017253170103772), (20380, 0.10165145500053267), (15787, 0.10165145500053267), (20384, 0.1016416604521975)]\n",
      "Average Clustering Coefficient: 0.7373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to compute network statistics\n",
    "def network_stats(G, name):\n",
    "    print(f\"\\n=== {name} Network Statistics ===\")\n",
    "    print(f\"Number of Nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of Edges: {G.number_of_edges()}\")\n",
    "    print(f\"Density: {nx.density(G):.4f}\")\n",
    "\n",
    "    # Degree Centrality\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    top_degrees = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"Top 5 Most Connected Nodes (Degree Centrality): {top_degrees}\")\n",
    "\n",
    "    # Betweenness Centrality\n",
    "    betweenness_centrality = nx.betweenness_centrality(G)\n",
    "    top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"Top 5 Most Influential Nodes (Betweenness Centrality): {top_betweenness}\")\n",
    "\n",
    "    # Eigenvector Centrality (Who is connected to important nodes?)\n",
    "    eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "    top_eigenvector = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    print(f\"Top 5 Most Influential Nodes (Eigenvector Centrality): {top_eigenvector}\")\n",
    "\n",
    "    # Clustering Coefficient (Measures local connectedness)\n",
    "    avg_clustering = nx.average_clustering(G)\n",
    "    print(f\"Average Clustering Coefficient: {avg_clustering:.4f}\")\n",
    "\n",
    "# Compute statistics for both networks\n",
    "network_stats(G_USA, \"USA\")\n",
    "network_stats(G_Denmark, \"Denmark\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polarization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
